{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: CNN-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验准备\n",
    "* 熟悉python语言的使用和numpy,torch的基本用法\n",
    "* 熟悉神经网络的训练过程与优化方法\n",
    "* 结合理论课的内容,了解卷积与卷积神经网络(CNN)的内容和原理\n",
    "* 了解常用的CNN模型的基本结构,如AlexNet,Vgg,ResNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验过程\n",
    "### 1. 卷积与卷积层\n",
    "\n",
    "- numpy实现卷积\n",
    "- pytorch中的卷积层和池化层\n",
    "\n",
    "### 2. CNN\n",
    "\n",
    "- 实现并训练一个基本的CNN网络\n",
    "- ResNet\n",
    "- VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积\n",
    "\n",
    "![conv](pics/conv2d.gif)\n",
    "\n",
    "在实验课上我们已经了解过卷积运算的操作当我们对一张二维的图像做卷积时,将卷积核沿着图像进行滑动乘加即可(如上图所示).\n",
    "\n",
    "\n",
    "下面的conv函数实现了对二维**单通道**图像的卷积.考虑输入的卷积核kernel的长宽相同,padding为对图像的四个边缘补0,stride为卷积核窗口滑动的步长."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convolution(img, kernel, padding=1, stride=1):\n",
    "    \"\"\"\n",
    "    img: input image with one channel\n",
    "    kernel: convolution kernel\n",
    "    \"\"\"\n",
    "    \n",
    "    h, w = img.shape\n",
    "    kernel_size = kernel.shape[0]\n",
    "    \n",
    "    # height and width of image with padding \n",
    "    ph, pw = h + 2 * padding, w + 2 * padding\n",
    "    padding_img = np.zeros((ph, pw))\n",
    "    padding_img[padding:h + padding, padding:w + padding] = img\n",
    "    \n",
    "    # height and width of output image\n",
    "    result_h = (h + 2 * padding - kernel_size) // stride + 1\n",
    "    result_w = (w + 2 * padding - kernel_size) // stride + 1\n",
    "    \n",
    "    result = np.zeros((result_h, result_w))\n",
    "    \n",
    "    # convolution\n",
    "    x, y = 0, 0\n",
    "    for i in range(0, ph - kernel_size + 1, stride):\n",
    "        for j in range(0, pw - kernel_size + 1, stride):\n",
    "            roi = padding_img[i:i+kernel_size, j:j+kernel_size]\n",
    "            result[x, y] = np.sum(roi * kernel)\n",
    "            y += 1\n",
    "        y = 0\n",
    "        x += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面在图像上简单一下测试我们的conv函数,这里使用3\\*3的高斯核对下面的图像进行滤波.\n",
    "![lena](pics/lena.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "img = Image.open('pics/lena.jpg').convert('L')\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  a Laplace kernel\n",
    "laplace_kernel = np.array([[-1, -1, -1],\n",
    "                           [-1, 8, -1],\n",
    "                           [-1, -1, -1]])\n",
    "\n",
    "# Gauss kernel with kernel_size=3\n",
    "gauss_kernel3 = (1/ 16) * np.array([[1, 2, 1], \n",
    "                                   [2, 4, 2], \n",
    "                                   [1, 2, 1]])\n",
    "\n",
    "# Gauss kernel with kernel_size=5\n",
    "gauss_kernel5 = (1/ 84) * np.array([[1, 2, 3, 2, 1],\n",
    "                                    [2, 5, 6, 5, 2], \n",
    "                                    [3, 6, 8, 6, 3],\n",
    "                                    [2, 5, 6, 5, 2],\n",
    "                                    [1, 2, 3, 2, 1]])\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 8))\n",
    "\n",
    "laplace_img = convolution(np.array(img), laplace_kernel, padding=1, stride=1)\n",
    "ax[0].imshow(Image.fromarray(laplace_img), cmap='gray')\n",
    "ax[0].set_title('laplace')\n",
    "\n",
    "gauss3_img = convolution(np.array(img), gauss_kernel3, padding=1, stride=1)\n",
    "ax[1].imshow(Image.fromarray(gauss3_img), cmap='gray')\n",
    "ax[1].set_title('gauss kernel_size=3')\n",
    "\n",
    "gauss5_img = convolution(np.array(img), gauss_kernel5, padding=2, stride=1)\n",
    "ax[2].imshow(Image.fromarray(gauss5_img), cmap='gray')\n",
    "ax[2].set_title('gauss kernel_size=5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面我们实现了实现了对单通道输入单通道输出的卷积.在CNN中,一般使用到的都是多通道输入多通道输出的卷积,要实现多通道的卷积, 我们只需要对循环调用上面的conv函数即可."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myconv2d(features, weights,  padding=0, stride=1):\n",
    "    \"\"\"\n",
    "    features: input, in_channel * h * w\n",
    "    weights: kernel, out_channel * in_channel * kernel_size * kernel_size\n",
    "    return output with out_channel\n",
    "    \"\"\"\n",
    "    in_channel, h, w = features.shape\n",
    "    out_channel, _, kernel_size, _ = weights.shape\n",
    "    \n",
    "    # height and width of output image\n",
    "    output_h = (h + 2 * padding - kernel_size) // stride + 1\n",
    "    output_w = (w + 2 * padding - kernel_size) // stride + 1\n",
    "    output = np.zeros((out_channel, output_h, output_w))\n",
    "    \n",
    "    # call convolution out_channel * in_channel times\n",
    "    for i in range(out_channel):\n",
    "        weight = weights[i]\n",
    "        for j in range(in_channel):\n",
    "            feature_map = features[j]\n",
    "            kernel = weight[j]\n",
    "            output[i] += convolution(feature_map, kernel, padding, stride)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来, 让我们测试我们写好的myconv2d函数."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=[\n",
    "           [[0,0,2,2,0,1],\n",
    "            [0,2,2,0,0,2],\n",
    "            [1,1,0,2,0,0],\n",
    "            [2,2,1,1,0,0],\n",
    "            [2,0,1,2,0,1],\n",
    "            [2,0,2,1,0,1]],\n",
    "\n",
    "           [[2,0,2,1,1,1],\n",
    "            [0,1,0,0,2,2],\n",
    "            [1,0,0,2,1,0],\n",
    "            [1,1,1,1,1,1],\n",
    "            [1,0,1,1,1,2],\n",
    "            [2,1,2,1,0,2]]\n",
    "            ]\n",
    "weights_data=[[ \n",
    "               [[ 0, 1, 0],\n",
    "                [ 1, 1, 1],\n",
    "                [ 0, 1, 0]],\n",
    "    \n",
    "               [[-1, -1, -1],\n",
    "                [ -1, 8, -1],\n",
    "                [ -1, -1, -1]] \n",
    "           ]]\n",
    "\n",
    "# numpy array\n",
    "input_data   = np.array(input_data)\n",
    "weights_data = np.array(weights_data)\n",
    "\n",
    "# show the result\n",
    "print(myconv2d(input_data, weights_data, padding=3, stride=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在Pytorch中,已经为我们提供了卷积和卷积层的实现.使用同样的input和weights,以及stride,padding,pytorch的卷积的结果应该和我们的一样.可以在下面的代码中进行验证."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "input_tensor = torch.tensor(input_data).unsqueeze(0).float()\n",
    "\n",
    "F.conv2d(input_tensor, weight=torch.tensor(weights_data).float(), bias=None, stride=3, padding=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 作业:\n",
    "上述代码中convolution的实现只考虑卷积核以及padding和stride长宽一致的情况,若输入的卷积核可能长宽不一致,padding与stride的输入可能为两个元素的元祖(代表两个维度上的padding与stride)并使用下面test input对你的convolutionV2进行测试."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutionV2(img, kernel, padding=(0,0), stride=(1,1)):\n",
    "    # To-Do\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test input\n",
    "test_input = np.array([[1, 1, 2, 1],\n",
    "                       [0, 1, 0, 2],\n",
    "                       [2, 2, 0, 2],\n",
    "                       [2, 2, 2, 1],\n",
    "                       [2, 3, 2, 3]])\n",
    "\n",
    "test_kernel = np.array([[1, 0], [0, 1], [0, 0]])\n",
    "\n",
    "# output\n",
    "print(convolutionV2(test_input, test_kernel, padding=(1, 0), stride=(1, 1)))\n",
    "\n",
    "print(convolutionV2(test_input, test_kernel, padding=(2, 1), stride=(1, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积层\n",
    "Pytorch提供了卷积层和池化层供我们使用.\n",
    "\n",
    "卷积层与上面相似, 而池化层与卷积层相似,Pooling layer的主要目的是缩小features的size.常用的有MaxPool(滑动窗口取最大值)与AvgPool(滑动窗口取均值)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "x = torch.randn(1, 1, 32, 32)\n",
    "\n",
    "conv_layer = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=1, padding=0)\n",
    "y = conv_layer(x)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**请问**:\n",
    "1. 输入与输出的tensor的size分别是多少?该卷积层的参数量是多少?\n",
    "2. 若kernel_size=5,stride=2,padding=2, 输出的tensor的size是多少?在上述代码中改变参数后试验后并回答.\n",
    "3. 若输入的tensor size为N\\*C\\*H\\*W,若第5行中卷积层的参数为in_channels=C,out_channels=Cout,kernel_size=k,stride=s,padding=p,那么输出的tensor size是多少? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**答**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input N * C * H * W\n",
    "x = torch.randn(1, 1, 4, 4)\n",
    "\n",
    "# maxpool\n",
    "maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "y = maxpool(x)\n",
    "\n",
    "# avgpool\n",
    "avgpool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "z = avgpool(x)\n",
    "\n",
    "#avgpool\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU\n",
    "我们可以选择在cpu或gpu上来训练我们的模型.   \n",
    "实验室提供了4卡的gpu服务器,要查看各个gpu设备的使用情况,可以在服务器上的jupyter主页点击new->terminal,在terminal中输入nvidia-smi即可查看每张卡的使用情况.如下图.\n",
    "![nvidia-smi](pics/nvidia-smi.png)\n",
    "上图左边一栏显示了他们的设备id(0,1,2,3),风扇转速,温度,性能状态,能耗等信息,中间一栏显示他们的bus-id和显存使用量,右边一栏是GPU使用率等信息.注意到中间一栏的显存使用量,在训练模型前我们可以根据空余的显存来选择我们使用的gpu设备.   \n",
    "在本次实验中我们将代码中的torch.device('cuda:0')的0更换成所需的设备id即可选择在相应的gpu设备上运行程序."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN(卷积神经网络)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一个简单的CNN\n",
    "\n",
    "接下来,让我们建立一个简单的CNN分类器.\n",
    "这个CNN的整体流程是    \n",
    "卷积(Conv2d) -> BN(batch normalization) -> 激励函数(ReLU) -> 池化(MaxPooling) ->     \n",
    "卷积(Conv2d) -> BN(batch normalization) -> 激励函数(ReLU) -> 池化(MaxPooling) ->    \n",
    "全连接层(Linear) -> 输出."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "\n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_size, num_classes):\n",
    "        super(MyCNN, self).__init__()\n",
    "        # conv1: Conv2d -> BN -> ReLU -> MaxPool\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        # conv2: Conv2d -> BN -> ReLU -> MaxPool\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        # fully connected layer\n",
    "        self.fc = nn.Linear(32 * (image_size // 4) * (image_size // 4), num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        input: N * 3 * image_size * image_size\n",
    "        output: N * num_classes\n",
    "        \"\"\"\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # view(x.size(0), -1): change tensor size from (N ,H , W) to (N, H*W)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.fc(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样,一个简单的CNN模型就写好了.与前面的课堂内容相似,我们需要对完成网络进行训练与评估的代码."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss_func, optimizer, device):\n",
    "    \"\"\"\n",
    "    train model using loss_fn and optimizer in an epoch.\n",
    "    model: CNN networks\n",
    "    train_loader: a Dataloader object with training data\n",
    "    loss_func: loss function\n",
    "    device: train on cpu or gpu device\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    # train the model using minibatch\n",
    "    for i, (images, targets) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = loss_func(outputs, targets)\n",
    "\n",
    "        # backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # every 100 iteration, print loss\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print (\"Step [{}/{}] Train Loss: {:.4f}\"\n",
    "                   .format(i+1, len(train_loader), loss.item()))\n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    model: CNN networks\n",
    "    val_loader: a Dataloader object with validation data\n",
    "    device: evaluate on cpu or gpu device\n",
    "    return classification accuracy of the model on val dataset\n",
    "    \"\"\"\n",
    "    # evaluate the model\n",
    "    model.eval()\n",
    "    # context-manager that disabled gradient computation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (images, targets) in enumerate(val_loader):\n",
    "            # device: cpu or gpu\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            # return the maximum value of each row of the input tensor in the \n",
    "            # given dimension dim, the second return vale is the index location\n",
    "            # of each maxium value found(argmax)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            \n",
    "            \n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "            total += targets.size(0)\n",
    "            \n",
    "        accuracy = correct / total\n",
    "        print('Accuracy on Test Set: {:.4f} %'.format(100 * accuracy))\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, save_path):\n",
    "    # save model\n",
    "    torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_curve(ys, title):\n",
    "    \"\"\"\n",
    "    plot curlve for Loss and Accuacy\n",
    "    Args:\n",
    "        ys: loss or acc list\n",
    "        title: loss or accuracy\n",
    "    \"\"\"\n",
    "    x = np.array(range(len(ys)))\n",
    "    y = np.array(ys)\n",
    "    plt.plot(x, y, c='b')\n",
    "    plt.axis()\n",
    "    plt.title('{} curve'.format(title))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('{}'.format(title))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准备数据与训练模型\n",
    "接下来，我们使用CIFAR10数据集来对我们的CNN模型进行训练.\n",
    "\n",
    "CIFAR-10:该数据集共有60000张彩色图像,这些图像是32\\*32,分为10个类,每类6000张图.这里面有50000张用于训练,构成了5个训练批,每一批10000张图;另外10000用于测试,单独构成一批.在本次实验中,使用CIFAR-10数据集来训练我们的模型.我们可以用torchvision.datasets.CIFAR10来直接使用CIFAR10数据集.\n",
    "![cifar10](pics/cifar10.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# mean and std of cifar10 in 3 channels \n",
    "cifar10_mean = (0.49, 0.48, 0.45)\n",
    "cifar10_std = (0.25, 0.24, 0.26)\n",
    "\n",
    "# define transform operations of train dataset \n",
    "train_transform = transforms.Compose([\n",
    "    # data augmentation\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar10_mean, cifar10_std)])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar10_mean, cifar10_std)])\n",
    "\n",
    "# torchvision.datasets provide CIFAR-10 dataset for classification\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data/',\n",
    "                                             train=True, \n",
    "                                             transform=train_transform,\n",
    "                                             download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data/',\n",
    "                                            train=False, \n",
    "                                            transform=test_transform)\n",
    "\n",
    "# Data loader: provides single- or multi-process iterators over the dataset.\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练过程中使用交叉熵(cross-entropy)损失函数与Adam优化器来训练我们的分类器网络.\n",
    "阅读下面的代码并在To-Do处,根据之前所学的知识,补充前向传播和反向传播的代码来实现分类网络的训练."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, num_epochs, optimizer, device):\n",
    "    \"\"\"\n",
    "    train and evaluate an classifier num_epochs times.\n",
    "    We use optimizer and cross entropy loss to train the model. \n",
    "    Args: \n",
    "        model: CNN network\n",
    "        num_epochs: the number of training epochs\n",
    "        optimizer: optimize the loss function\n",
    "    \"\"\"\n",
    "        \n",
    "    # loss and optimizer\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.to(device)\n",
    "    loss_func.to(device)\n",
    "    \n",
    "    # log train loss and test accuracy\n",
    "    losses = []\n",
    "    accs = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print('Epoch {}/{}:'.format(epoch + 1, num_epochs))\n",
    "        # train step\n",
    "        loss = train(model, train_loader, loss_func, optimizer, device)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        # evaluate step\n",
    "        accuracy = evaluate(model, test_loader, device)\n",
    "        accs.append(accuracy)\n",
    "        \n",
    "    \n",
    "    # show curve\n",
    "    show_curve(losses, \"train loss\")\n",
    "    show_curve(accs, \"test accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "num_epochs = 10\n",
    "lr = 0.01\n",
    "image_size = 32\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare and define an objet of MyCNN\n",
    "mycnn = MyCNN(image_size, num_classes)\n",
    "print(mycnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration, cpu, cuda:0/1/2/3 available\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "optimizer = torch.optim.Adam(mycnn.parameters(), lr=lr)\n",
    "\n",
    "# start training on cifar10 dataset\n",
    "fit(mycnn, num_epochs, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet\n",
    "接下来,让我们完成更复杂的CNN的实现.  \n",
    "ResNet又叫做残差网络.在ResNet网络结构中会用到两种残差模块，一种是以两个3\\*3的卷积网络串接在一起作为一个残差模块，另外一种是1\\*1、3\\*3、1\\*1的3个卷积网络串接在一起作为一个残差模块。他们如下图所示。\n",
    "![ResNet](pics/block.png)\n",
    "我们以左边的模块为例实现一个ResidualBlock.注意到由于我们在两次卷积中可能会使输入的tensor的size与输出的tensor的size不相等,为了使它们能够相加,所以输出的tensor与输入的tensor size不同时,我们使用downsample(由外部传入)来使保持size相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在,试在**To-Do补充代码**完成下面的forward函数来完成ResidualBlock的实现,并运行它."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3x3 convolution\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "# Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the computation performed at every call.\n",
    "        x: N * C * H * W\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        # if the size of input x changes, using downsample to change the size of residual\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        \n",
    "        \"\"\"\n",
    "        To-Do: add code here\n",
    "        \"\"\"\n",
    "        \n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是一份针对cifar10数据集的ResNet的实现.   \n",
    "它先通过一个conv3x3,然后经过3个包含多个残差模块的layer(一个layer可能包括多个ResidualBlock, 由传入的layers列表中的数字决定), 然后经过一个全局平均池化层,最后通过一个线性层."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        \"\"\"\n",
    "        block: ResidualBlock or other block\n",
    "        layers: a list with 3 positive num.\n",
    "        \"\"\"\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(3, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # layer1: image size 32\n",
    "        self.layer1 = self.make_layer(block, 16, num_blocks=layers[0])\n",
    "        # layer2: image size 32 -> 16\n",
    "        self.layer2 = self.make_layer(block, 32, num_blocks=layers[1], stride=2)\n",
    "        # layer1: image size 16 -> 8\n",
    "        self.layer3 = self.make_layer(block, 64, num_blocks=layers[2], stride=2)\n",
    "        # global avg pool: image size 8 -> 1\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "    \n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def make_layer(self, block, out_channels, num_blocks, stride=1):\n",
    "        \"\"\"\n",
    "        make a layer with num_blocks blocks.\n",
    "        \"\"\"\n",
    "        \n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            # use Conv2d with stride to downsample\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        \n",
    "        # first block with downsample\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        \n",
    "        self.in_channels = out_channels\n",
    "        # add num_blocks - 1 blocks\n",
    "        for i in range(1, num_blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "            \n",
    "        # return a layer containing layers\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        # view: here change output size from 4 dimensions to 2 dimensions\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet = ResNet(ResidualBlock, [2, 2, 2])\n",
    "print(resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用fit函数训练实现的ResNet,观察结果变化."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "num_epochs = 10\n",
    "lr = 0.001\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0')\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=lr)\n",
    "\n",
    "fit(resnet, num_epochs, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 作业\n",
    "尝试改变学习率lr,使用SGD或Adam优化器,训练10个epoch,提高ResNet在测试集上的accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 作业\n",
    "下图表示将SE模块嵌入到ResNet的残差模块.\n",
    "![SE-Resnet module](pics/se-resnet.png)\n",
    "其中,global pooling表示全局池化层(将输入的size池化为1\\*1), 将c\\*h\\*w的输入变为c\\*1\\*1的输出.FC表示全连接层(线性层),两层FC之间使用ReLU作为激活函数.通过两层FC后使用sigmoid激活函数激活.最后将得到的c个值与原输入c\\*h\\*w按channel相乘,得到c\\*h\\*w的输出.\n",
    "\n",
    "补充下方的代码完成SE-Resnet block的实现."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        # The output of AdaptiveAvgPool2d is of size H x W, for any input size.\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \"\"\"\n",
    "        To-Do: add code here\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        To-Do: add code here\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, reduction=16):\n",
    "        super(SEResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.se = SELayer(out_channels, reduction)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        residual = x\n",
    "        \"\"\"\n",
    "        To-Do: add code here\n",
    "        \"\"\"\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_resnet = ResNet(SEResidualBlock, [2, 2, 2])\n",
    "print(se_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "num_epochs = 10\n",
    "lr = 0.001\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0')\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(se_resnet.parameters(), lr=lr)\n",
    "\n",
    "fit(se_resnet, num_epochs, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vgg\n",
    "接下来让我们阅读vgg网络的实现代码.VGGNet全部使用3\\*3的卷积核和2\\*2的池化核，通过不断加深网络结构来提升性能。Vgg表明了卷积神经网络的深度增加和小卷积核的使用对网络的最终分类识别效果有很大的作用.\n",
    "![vgg](pics/vgg_architectures.png)\n",
    "下面是一份用于训练cifar10的简化版的vgg代码.   \n",
    "有时间的同学可以阅读并训练它."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg)\n",
    "        # linear layer\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        \"\"\"\n",
    "        cfg: a list define layers this layer contains\n",
    "            'M': MaxPool, number: Conv2d(out_channels=number) -> BN -> ReLU\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "vggnet = VGG(cfg['VGG11'])\n",
    "print(vggnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "num_epochs = 10\n",
    "lr = 1e-3\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(vggnet.parameters(), lr=lr)\n",
    "\n",
    "fit(vggnet, num_epochs, optimizer, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
